{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cycliclr import CyclicLR\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_df_bcolz(dframe, bcolz_arr, batch_size, shuffle=True, yielder=lambda x: x):\n",
    "    assert(batch_size % bcolz_arr.chunklen == 0)\n",
    "    chunks_per_batch = batch_size // bcolz_arr.chunklen\n",
    "    init_bounds = bcolz_arr.partitions\n",
    "    if bcolz_arr.leftover_elements > 0:\n",
    "        init_bounds.append((init_bounds[-1][1], len(bcolz_arr)))\n",
    "    while True:\n",
    "        bounds = np.random.permutation(init_bounds) if shuffle else init_bounds\n",
    "        feats_chunks, scores_chunks = [], []\n",
    "        def return_batch():\n",
    "            feats = np.concatenate(feats_chunks, axis=0)\n",
    "            scores = np.concatenate(scores_chunks, axis=0)\n",
    "            feats_chunks.clear()\n",
    "            scores_chunks.clear()\n",
    "            return yielder((feats, scores))\n",
    "        chunks = 0\n",
    "        for start, stop in bounds:\n",
    "            feats_chunks.append(bcolz_arr[start:stop])\n",
    "            scores_chunks.append(np.array(dframe[start:stop].score, dtype='float32'))\n",
    "            chunks += 1\n",
    "            if chunks % chunks_per_batch == 0:\n",
    "                yield return_batch()\n",
    "        if len(feats_chunks) > 0:\n",
    "            yield return_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bcolz_array_iterator import BcolzArrayIterator\n",
    "\n",
    "def batch_generator_bcolz(data, batch_size, shuffle=True):\n",
    "    batch_generator_bcolz = BcolzArrayIterator(data, batch_size=batch_size, shuffle=shuffle)\n",
    "    while True:\n",
    "        feats = next(batch_generator_bcolz)\n",
    "        yield feats, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_generator_df(data, batch_size, shuffle=True):\n",
    "    while True:\n",
    "        data_ = data.sample(frac=1) if shuffle else data\n",
    "        for iteration, batch in data_.groupby(np.arange(len(data)) // batch_size):\n",
    "            fens = [f.strip() for f in batch.fen.tolist()]\n",
    "            feats = np.stack([get_feats(Position.from_fen(fen)) for fen in fens])\n",
    "            yield feats, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model.compile(keras.optimizers.SGD(lr=.01, momentum=.95, nesterov=True), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "#nvalid = len(features_sf12_valid)\n",
    "\n",
    "x = features_sf12_sample\n",
    "x_valid = features_sf12_valid_sample\n",
    "\n",
    "# yielder = lambda f_s: (f_s[0], [f_s[0], f_s[1]]) # (feats, [feats, scores])\n",
    "train_gen = batch_generator_df_bcolz(sf_scores12, x, batch_size)\n",
    "valid_gen = batch_generator_df_bcolz(sf_scores12[-60000:], x_valid, batch_size, shuffle=False)\n",
    "\n",
    "train_steps = ceil(len(x) / batch_size)\n",
    "valid_steps = ceil(len(x_valid) / batch_size)\n",
    "\n",
    "# lr_plateau = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('../slonik_data/autoencoder_v0_weights.{epoch:03d}-{val_loss:.6f}.h5', \n",
    "                                             monitor='val_loss', save_best_only=True, save_weights_only=True, period=1)\n",
    "# stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, mode='auto')\n",
    "clr = CyclicLR(base_lr=0., max_lr=2, step_size=train_steps*10, mode='triangular')\n",
    "# clr = CyclicLR(base_lr=0, max_lr=1e-2, step_size=train_steps*5, mode='triangular')\n",
    "\n",
    "callbacks = [clr]\n",
    "# callbacks = [clr, checkpoint]\n",
    "# K.set_value(train_model.optimizer.lr, 1e-3)\n",
    "train_model.fit_generator(train_gen, train_steps, epochs=10, \n",
    "                          validation_data=valid_gen, validation_steps=valid_steps, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(clr.history['iterations'], clr.history['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.s_[:60]\n",
    "plt.plot(clr.history['lr'][rng], clr.history['loss'][rng])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024 * 2\n",
    "valid_steps = ceil(len(features_sf12_valid) / batch_size)\n",
    "valid_gen = batch_generator_bcolz(features_sf12_valid, batch_size, shuffle=False)\n",
    "#yielder=lambda f_s: (f_s[0], [f_s[0], f_s[1]]))\n",
    "# autoencoder.evaluate_generator(valid_gen, steps=valid_steps)\n",
    "# train_model.evaluate_generator(valid_gen, steps=valid_steps)\n",
    "# train_model.metrics_names\n",
    "# K.get_value(train_model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = slice(0,40)\n",
    "dfrng = slice(rng.start+-60000, rng.stop+-60000)\n",
    "fens = sf_scores12[dfrng].orig_fen\n",
    "scores = sf_scores12[dfrng].score\n",
    "# np.allclose(features_sf12_valid[rng], np.array([get_feats(Position.from_fen(f)) for f in fens]))\n",
    "# pprint(list(zip(scores, evaluator.predict(features_sf12_valid[rng]).squeeze())))\n",
    "x = np.arange(len(scores))\n",
    "plt.plot(x, scores, 'r')\n",
    "plt.plot(x, model.predict(features_sf12_valid[rng]).squeeze(), 'b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
